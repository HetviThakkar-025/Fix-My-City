1. Basics of OpenCV — image loading, resizing, color conversion
2. Histogram comparison (color-based)
3. Image Hashing (pHash, aHash)
4. SSIM metric
5. Feature Matching using ORB/SIFT
6. CNN Feature Embedding (ResNet or MobileNet)
7. Combine scores + define thresholds
8. Build complete pipeline



When you're building a **Duplicate Report Detection System** using **text**, **location**, and **image similarity**, the final merging of reports works like this:

---

## 🧠 **Step-by-Step Merging Pipeline**

### ✅ 1. **Text Similarity Clustering**

* **Input:** Report titles + descriptions
* **Process:**

  * Convert text to vectors (using TF-IDF or Sentence Transformers)
  * Measure pairwise similarity (e.g., cosine similarity)
  * Cluster similar ones (e.g., with DBSCAN or threshold-based grouping)
* **Output:** Clusters of textually similar reports

---

### ✅ 2. **Location-Based Filtering (within each text cluster)**

* **Input:** Coordinates (latitude, longitude) of reports
* **Process:**

  * Use Haversine distance or geohashing
  * Group reports within a radius (e.g., 100 meters)
* **Output:** Subclusters with similar text *and* close locations

---

### ✅ 3. **Image Similarity Check (optional)**

* **Input:** Images from each subcluster
* **Process:**

  * Compute perceptual hashes (pHash/dHash/aHash)
  * Compare hashes using Hamming distance
  * Merge if images are visually similar (distance below a threshold like 5)
* **Output:** Final deduplicated report groupings

---

### ✅ 4. **Final Merge Logic**

Each group of:

* Similar **text**
* Near **location**
* (Optionally) similar **images**

...is considered **one real-world issue**.

You can then:

* Select the earliest/most detailed report as **primary**
* Aggregate others as **duplicates**
* Sum their upvotes to show **“Total Reports: 4”**
* Mark them in DB with a `duplicateOf` field pointing to the main one

---

## 💡 Example

Let's say 3 users report:

* `"Pothole on road"` at Lat/Lng A with photo X
* `"Big pothole near temple"` at Lat/Lng A+20m with photo X
* `"Broken road near traffic signal"` at Lat/Lng A+30m with photo Y

### → System output:

* All have **similar text** (same keywords)
* All within **50 meters**
* Images are **visually same or near-identical**

✅ So → merged into 1 report:

```json
{
  "mainReportId": "abc123",
  "duplicates": ["def456", "ghi789"],
  "totalVotes": 3
}
```

---

## ✅ What You Store in DB

Each report could have:

* `duplicateOf`: ID of the main report if it’s a duplicate
* `isDuplicate: true/false`
* `mergedVotes`: count of duplicates + original
* `dedupClusterId`: optional UUID to track grouping

---

## 🔧 Tools You'll Use

| Purpose          | Tool / Algo                    |
| ---------------- | ------------------------------ |
| Text vectorizing | TF-IDF / Sentence Transformers |
| Similarity       | Cosine similarity              |
| Clustering       | DBSCAN / Agglomerative         |
| Geo grouping     | Haversine / GeoHash            |
| Image hashing    | pHash, dHash, aHash            |

---

## 🔚 Final Output View (in your app)

In UI:

* Show only one entry (the primary report)
* Display:
  🕳️ **“Pothole reported by 4 users”**
  ✅ Most upvoted comment
  📸 Representative image
  👍 15 total votes

---



---

## 🔁 What is an ML Pipeline?

An **ML pipeline** is a series of **steps** to go from **raw data → predictions**, just like an assembly line.

### 🔄 Typical ML Pipeline (for 1st model):

1. **Data Collection**
   → Your dataset (title, description, location, images)

2. **Preprocessing**

   * Text cleaning (lowercase, remove punctuation)
   * Tokenization
   * TF-IDF or embedding generation

3. **Feature Engineering**

   * Text → vector (TF-IDF, BERT, etc.)
   * Location → cluster using `DBSCAN`
   * Image → similarity hash (`pHash`) or image embedding (CNN)

4. **Similarity Calculation**

   * Cosine similarity (for text)
   * Euclidean distance or clustering label (for location)
   * Hamming distance (for images)

5. **Duplicate Detection Logic**

   * Combine the three similarity scores:

     ```
     final_score = (0.5 × text_similarity) + (0.3 × location_score) + (0.2 × image_score)
     ```
   * If `final_score > threshold`, mark as duplicate

6. **Output**

   * Merge into one report
   * Increment vote count

---

## ✅ How You Merge All in Model 1

Let’s walk through merging **text + location + image** similarity:

### 🔹 1. **Text Similarity**

* Combine `title + description` as a single input.
* Use TF-IDF or Sentence Transformers → generate vector
* Compare with past report vectors → get cosine similarity (0 to 1)

### 🔹 2. **Location Similarity**

* Use `latitude` and `longitude`
* Apply **DBSCAN** or Haversine distance
* Reports in same cluster or <200m → similar location

### 🔹 3. **Image Similarity**

* Use image URL → download image
* Convert to hash using `pHash` or extract embeddings using CNN
* Compare with existing hashes/embeddings → get similarity score

---

## 🧠 How to “Train” or Fine-Tune for This?

Actually, **you don’t train a full model** here. You're using **unsupervised techniques**:

| Component        | Training?     | Algorithm/Tool           |
| ---------------- | ------------- | ------------------------ |
| Text similarity  | ❌ No training | TF-IDF or embeddings     |
| Location cluster | ❌ No training | DBSCAN                   |
| Image similarity | ❌ No training | pHash or ResNet features |

So yes — if you **learn text similarity methods** (like TF-IDF, cosine similarity, Sentence Transformers), then yes you will:

* Take all title+description from dataset
* Convert to vectors
* Compare similarity with other reports

---

## 🔧 Example (Merging All)

```python
# Step 1: Vectorize text
text_vec1 = vectorizer.transform(["pothole near railway"])
text_vec2 = vectorizer.transform(["huge pothole near rail station"])
text_sim = cosine_similarity(text_vec1, text_vec2)

# Step 2: Location distance
loc1 = (23.04, 72.51)
loc2 = (23.042, 72.512)
loc_sim = haversine_distance(loc1, loc2) < 0.2  # <200m → True

# Step 3: Image similarity
hash1 = imagehash.phash(Image.open("img1.png"))
hash2 = imagehash.phash(Image.open("img2.png"))
img_sim = hash1 - hash2 < 5  # hamming distance < 5 → similar

# Step 4: Final decision
if text_sim > 0.8 and loc_sim and img_sim:
    print("Likely duplicate")
```

---

## 🧪 Your Final Output Will Be:

* Reports clustered as duplicates
* For each cluster → one master report with vote count (e.g., `vote: 3`)
* UI: show “This issue was reported by 3 users” instead of 3 separate reports

---

## ✅ So to summarize what you need to do now:

### 🧠 Learn:

* TF-IDF / cosine similarity
* DBSCAN
* Image hashing (pHash)

### 🔨 Implement:

* Step-by-step pipeline (above)
* Combine all 3 similarity scores
* Decide a threshold for duplicate (like score > 0.7)


---

### ✅ If you're building the **Duplicate Report Detection** model:

You **DO need** to load the dataset I generated — **but not to "train" a model**, rather to:

### 🔁 Use it for:

1. **Text vectorization** → Generate TF-IDF or embedding vectors for all past reports
2. **Location clustering** → Group existing reports using DBSCAN
3. **Image similarity comparison** → Compare uploaded image to existing images

---

### 🧠 Why you still need to load the dataset:

You're building an **unsupervised system**, not a trained classifier. That means:

* You’re comparing the **new incoming report** against all **existing reports**
* So you **must load existing reports from the dataset (CSV/JSON)**

---

### ✅ How you'll use it in practice:

```python
# Load dataset
import pandas as pd
data = pd.read_csv("reports_dataset.csv")

# Preprocess title+description
data["combined_text"] = data["title"] + " " + data["description"]

# Vectorize all existing reports using TF-IDF
from sklearn.feature_extraction.text import TfidfVectorizer
vectorizer = TfidfVectorizer()
tfidf_matrix = vectorizer.fit_transform(data["combined_text"])

# New report comes in
new_report = "There is a large pothole in the road near city hospital"
new_vec = vectorizer.transform([new_report])

# Compare with all existing
from sklearn.metrics.pairwise import cosine_similarity
similarities = cosine_similarity(new_vec, tfidf_matrix)

# Get top similar report
top_idx = similarities.argmax()
top_score = similarities[0][top_idx]
print(f"Most similar report: {data.iloc[top_idx]['title']} (Score: {top_score})")
```

---

### 🔁 Repeat similar logic for:

* **Location** (use `lat`, `lng` from dataset to apply DBSCAN clustering)
* **Image** (compare hash of new image with hash from dataset)

---

### ✅ So yes, for Model 1:

* You will **load the dataset** (CSV or JSON)
* You will **not train a model**
* Instead, you'll **compare incoming reports with past dataset** using similarity techniques

---

